{"name":"Cobe","body":"COBE stands for Code of Business Ethics. Cobe is a conversation\r\nsimulator, originally a database backed port of MegaHAL but a bit\r\nmore now.\r\n\r\nThere are a few relevant posts here:\r\nhttp://teichman.org/blog/2011/09/cobe-2.0.html\r\nhttp://teichman.org/blog/2011/05/singularity.html\r\nhttp://teichman.org/blog/2011/02/cobe.html\r\n\r\nYou can read its release history here:\r\nhttps://github.com/pteichman/cobe/wiki\r\n\r\nCobe has been inspired by the success of Hailo:\r\nhttp://blogs.perl.org/users/aevar_arnfjor_bjarmason/2010/01/hailo-a-perl-rewrite-of-megahal.html\r\n\r\nOur goals are similar to Hailo: an on-disk data store for lower memory\r\nusage, better support for Unicode, and general stability.\r\n\r\nYou can read about the original MegaHAL here:\r\nhttp://megahal.alioth.debian.org/How.html\r\n\r\nIn short, it uses Markov modeling to generate text responses after\r\nlearning from input text.\r\n\r\nCobe creates a directed graph of word n-grams (default n=3) from the\r\ntext it learns. When generating a response, it performs random walks\r\non this graph to create as many candidate replies as it can in half a\r\nsecond.\r\n\r\nAs the candidate responses are created, they're run through a scoring\r\nalgorithm that identifies which is the best of the group. After the\r\nhalf second is over, the best candidate is returned as the response.\r\n\r\nCobe installs a command line tool (called cobe) for interacting with a\r\nbrain database, though it is also intended to be used as a Python\r\napi. See the documentation in the cobe.brain module for details.\r\n\r\nTo install from a tarball:\r\n\r\n  $ python setup.py install\r\n\r\nOr from the Python Package Index:\r\n\r\n  $ easy_install pip\r\n  # pip install cobe\r\n\r\nUsage:\r\n\r\n  $ cobe init\r\n  $ cobe learn <text file>\r\n  $ cobe console\r\n","tagline":"A Markov chain based text generation library and MegaHAL style chatbot","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}